# March 8 2018

## MultiProcessing Systems

- **Independent Parallelism**
    - Process are separate applications
    - No synchronization among processes
    - Properties similar to uniprocessor system
    - e.g. Word processing, shell, mail, browser

### Types of Parallelism
1. **Coarse and Very Coarse-Grained Parallelism**
    - Very Coarse: Distributed processing across network nodes
    - Coarse: Multiprocessing of concurrent processes in a multiprogramming environment
    - Little synchronization among processes
        - Good for concurrent processes running on a multiprogrammed uniprocessor
2. **Medium-Grained Parallelism**
    - Parallel processing or multitasking within a single application
    - Threats interact frequently and share data
    - Requires synchronization
3. **Fine-Grained Parallelism**
    - Parallelism inherit in single instruction stream
    - Highly parallel applications
    

### Scheduling Design Issues
    - Scheduler needs to consider
        - Assignment of processes to processors
        - Use of multiprogramming on individual processors
        - Dispatching of process

#### Assignment of Processes to Processors
- Two architectures
    1. **Uniform multiprocessor**
        - Assign processes to dedicated processor
        - Migrate processes between processors
        - Can use static assignment, process migration, or dynamic load balancing
        - _Static assignment_
            - Low overhead, one decision made
            - Allows group/gang scheduling
            - Processor can be idle
        - _Process migration_
            - Large overhead
        - _Dynamic load balancing_
            - Static assignment but sometimes migrate
    2. **Heterogeneous multiprocessor**
        - Requires special software
- Master/slave architecture
    - Key kernal functions run by certain processor (e.g. in Linux)
    - Master responsible for scheduling
    - Slave sends service request to master and waits for result
    - **Pros**: 
        - Simple design
    - **Cons**:
        - Master failure can result in system failure
        - Master is a performance bottleneck
- Peer architecture
    - Kernal can execute on any processor
    - Each processor does self scheduling
    - Complicated, as two processors cannot choose the same process

#### Thread Scheduling
    - Uniprocessor
        - Program structuring aid
        - Overlap I/O with processing
        - Lower management overhead
    - Multiprocessor
        - True parallelism

#### Load sharing
    - Processes are not assigned to a certain processor
    - Global queue, processor picks processes
    - Evenly distribute load
    - **Pros:**
        - No processor is left idle with available processes
        - No centralized scheduler required
        - Easy to implement
    - **Cons:**:
        - Central queue needs mutual exclusion
        - If all threads in global queue, all threads will not gain access to processors at the same time
#### Gang scheduling
    - Set of related threads are set to run on a set of processors at the same time